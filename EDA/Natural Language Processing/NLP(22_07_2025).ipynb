{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra34izR0SfZ4"
   },
   "source": [
    "#**NLP (Natural Language Process) :-**\n",
    "* It is the field of AI that focuses on the interaction btw Machine and Human language.\n",
    "* It enables machine to read, understand, interpret, and generate human language.\n",
    "\n",
    "###**Task in NLP**\n",
    "1. Text Classification.\n",
    "2. Sentiment Analysis.\n",
    "3. Language Translation.\n",
    "4. Speech Recognition.\n",
    "5. Chat bots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuDM7a7WXVI9"
   },
   "source": [
    "**Corpus :-**\n",
    "* It is a large set of text data.\n",
    "* Used for training the machine.\n",
    "\n",
    "##**Step of NLP**\n",
    "Raw Text\n",
    "* â†’ Lowercasing the text\n",
    "* â†’ Tokenization\n",
    "* â†’ Remove Punctuation\n",
    "* â†’ Remove Stopwords\n",
    "* â†’ Stemming / Lemmatization\n",
    "* â†’ Cleaned Tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdtT3Q0dYIaz"
   },
   "source": [
    "###**Tokenization:-**\n",
    "* Splitting text into words smaller parts,called Token.\n",
    "* It can be a word, characters or subwords.   \n",
    "\n",
    "###**Stemming:-**\n",
    "* It the process of removing suffixes from the word to reduce it to its base/root form.\n",
    "* It does't always give a real word just a rough root. (e.g.-`running` â†’ `run`)\n",
    "\n",
    "###**Regexp Stemming**\n",
    "* It work by applying a regular expression pattern to each word to remove suffixes or specific endings and optionally enforeces a minimum stem length.\n",
    "\n",
    "**____Parameters of regxp stemming**\n",
    "\n",
    "**1.regexp --> STR()**\n",
    "* The regular expression pattern to removes matching suffixes form the words.\n",
    "* This should be a pattern that matches the suffix you want to remove.\n",
    "\n",
    "**2.MIN--int**\n",
    "* The minimum length a stemmed word must have if stemming would make the word shorted than (min) the word is return unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnt1kyVMg9Ba"
   },
   "source": [
    "###**Wordnet Lemmatizer :-**\n",
    "* It is a tool in NLP that reduces a word to its base or dictionary form know as lemma.\n",
    "* Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KobP36eRhxx1"
   },
   "source": [
    "##**Key Difference btw Stemmer and Lemmatizer**\n",
    "###**ðŸ”¹ Stemming:**\n",
    "* Word ka suffix/prefix kaat kar root form me convert karta hai.\n",
    "* Ye rule-based ya algorithm-based hota hai.\n",
    "* Result grammatically correct nahi bhi ho sakta.\n",
    "\n",
    "**ðŸ”¸ Example:**\n",
    "    \n",
    "    \"playing\" â†’ \"play\"\n",
    "    \"played\" â†’ \"play\"\n",
    "    \"plays\" â†’ \"play\"\n",
    "    \"player\" â†’ \"playe\" âŒ (wrong root)\n",
    "\n",
    "###**ðŸ”¹ Lemmatization:**\n",
    "* Word ko uske dictionary ke root word (lemma) me convert karta hai.\n",
    "* Isme word ka part-of-speech (POS) ka bhi use hota hai.\n",
    "* Result grammatically correct hota hai.\n",
    "\n",
    "**ðŸ”¸ Example:**   \n",
    "\n",
    "    \"playing\" â†’ \"play\"\n",
    "    \"better\" â†’ \"good\"\n",
    "    \"was\" â†’ \"be\"\n",
    "    \"mice\" â†’ \"mouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkFP2L-uj7dT"
   },
   "source": [
    "###**ðŸ§  Stemmer ka use kyun hota hai jab lemmatizer available hai?**\n",
    "**âœ… 1. Speed matters more than correctness (real-time systems me)**\n",
    "\n",
    "Lemmatizer slow hota hai â€” kyunki:\n",
    "* Dictionary lookup karta hai.\n",
    "* POS tagging karta hai.\n",
    "\n",
    "**âž¡ï¸ Jab millions of documents ya real-time user queries ko process karna ho â€” toh stemmer ka speed kaafi kaam aata hai.**\n",
    "\n",
    "**ðŸ”¸ Example:** Google jese search engine ke backend me stemmer use hota hai for query expansion, jahan fast response chahiye.\n",
    "\n",
    "**âœ… 2. Low memory / Low compute environments**\n",
    "* Lemmatizer ko WordNet jese lexical databases chahiye.\n",
    "* Ye large in size hote hain aur zyada RAM/CPU chahte hain.\n",
    "\n",
    "âž¡ï¸ Lekin agar aapke paas low-end mobile device, chatbot, IoT device hai â€” toh stemmer lightweight aur perfect fit hota hai.\n",
    "\n",
    "âœ… 3. Use-case me exact word important nahi hota\n",
    "Agar task me sirf word grouping ya token normalization chahiye (jaise: indexing, tagging, search), tab lemmatization ki accuracy zaruri nahi hoti.\n",
    "\n",
    "ðŸ”¸ Example:\n",
    "â€œconnectâ€, â€œconnectedâ€, â€œconnectingâ€ â€” stemmer inhe â€œconnectâ€ ya â€œconnectiâ€ banata hai, jo enough hai search matching ke liye.\n",
    "\n",
    "âœ… 4. Data cleaning phase me â€” fast pre-processing ke liye\n",
    "Jab ML pipeline me initial fast cleaning karni ho â€” tab stemmer use kar lete hain.\n",
    "\n",
    "Later, agar zarurat ho toh lemmatizer se refine kar lete hain.\n",
    "\n",
    "âœ… 5. Stemming works â€œgood enoughâ€ for many tasks\n",
    "NLP me har task ko high accuracy nahi chahiye.\n",
    "\n",
    "Kaafi tasks me stemmer ke 80â€“90% accurate result sufficient hote hain.\n",
    "\n",
    "Agar lemmatizer ka use karne se result sirf 2â€“3% better ho raha hai, lekin cost 10x badh rahi hai â€” toh stemmer prefer kiya jata hai.\n",
    "\n",
    "**ðŸ”š Final One-liner Answer: lemmatizer logically better hai â€” lekin stemmer aaj bhi use hota hai jab hume speed chahiye, memory kam ho, aur exact linguistic accuracy important na ho. Itâ€™s a trade-off between speed and correctness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vE3OakHQY6Lc",
    "outputId": "b50f219d-3078-4af8-ee6e-3a97cd5e11d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8-1h7lHa8mn",
    "outputId": "40e2e6e9-2168-4a6c-f01f-ed33ce7ca09e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KktejNk-ZGbR"
   },
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "today we are learning NLP, where sarthak sir is teaching about the corpus and tokenization of words and sentences.\n",
    "In the data science AI section 3 of BBDEG, Lucknow.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8HcjnSJZ3Wa"
   },
   "outputs": [],
   "source": [
    "#this will convert corpus into sentences.\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUKiqWl_airC"
   },
   "outputs": [],
   "source": [
    "st = sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhgJ5jG_amnB",
    "outputId": "583d66ea-ba0f-4b9a-843e-c27a0f492072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ntoday we are learning NLP, where sarthak sir is teaching about the corpus and tokenization of words and sentences.', 'In the data science AI section 3 of BBDEG, Lucknow.']\n"
     ]
    }
   ],
   "source": [
    "print(st(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAIsMARIapnN"
   },
   "outputs": [],
   "source": [
    "#this will convert corpus into words.\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko3lzdN7bwTG"
   },
   "outputs": [],
   "source": [
    "wt = word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qyecz2XKbzVs",
    "outputId": "adcfac65-4681-42aa-a9f3-86c32339a416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today', 'we', 'are', 'learning', 'NLP', ',', 'where', 'sarthak', 'sir', 'is', 'teaching', 'about', 'the', 'corpus', 'and', 'tokenization', 'of', 'words', 'and', 'sentences', '.', 'In', 'the', 'data', 'science', 'AI', 'section', '3', 'of', 'BBDEG', ',', 'Lucknow', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wt(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BoTgTWcb5pJ",
    "outputId": "eb9a6a5c-5584-4d99-a988-a7734c088d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "today we are learning NLP, where sarthak sir is teaching about the corpus and tokenization of words and sentences.\n",
      "In the data science AI section 3 of BBDEG, Lucknow.\n"
     ]
    }
   ],
   "source": [
    "for i in sent_tokenize(corpus):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MlMLTNCcEvn",
    "outputId": "c7760f1a-3658-405d-996a-4348bcd30e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today\n",
      "we\n",
      "are\n",
      "learning\n",
      "NLP\n",
      ",\n",
      "where\n",
      "sarthak\n",
      "sir\n",
      "is\n",
      "teaching\n",
      "about\n",
      "the\n",
      "corpus\n",
      "and\n",
      "tokenization\n",
      "of\n",
      "words\n",
      "and\n",
      "sentences\n",
      ".\n",
      "In\n",
      "the\n",
      "data\n",
      "science\n",
      "AI\n",
      "section\n",
      "3\n",
      "of\n",
      "BBDEG\n",
      ",\n",
      "Lucknow\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in word_tokenize(corpus):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PcQy6C2d-UD"
   },
   "source": [
    "**Stemming**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbAzgfBrdwJh"
   },
   "outputs": [],
   "source": [
    "words = [\"playing\",\"walking\",\"sleeping\",\"plays\",\"flying\",\"eating\",\"eats\",\"played\",\"walked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vng3Dla8ebq7"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFLPXZo7egMN"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qwLzuNQpei5q",
    "outputId": "6c3ec704-4eec-41b6-f448-a7adede01285"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for individuals\n",
    "ps.stem(\"playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRxLAFiUew5Q",
    "outputId": "8656b9f1-85b7-4e02-b35c-07490bfce45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing --> play\n",
      "walking --> walk\n",
      "sleeping --> sleep\n",
      "plays --> play\n",
      "flying --> fli\n",
      "eating --> eat\n",
      "eats --> eat\n",
      "played --> play\n",
      "walked --> walk\n"
     ]
    }
   ],
   "source": [
    "# by for loop\n",
    "for i in words:\n",
    "  print(i,\"-->\",ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6xnLN2lfpBK"
   },
   "outputs": [],
   "source": [
    "words = [\"flyed\",\"history\",\"killing\",\"killed\",\"jumping\",\"jumped\",\"study\",\"studying\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gb3zVUJ3f5rj",
    "outputId": "95d86264-36ef-44dd-f960-98a74b4e2634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flyed --> fli\n",
      "history --> histori\n",
      "killing --> kill\n",
      "killed --> kill\n",
      "jumping --> jump\n",
      "jumped --> jump\n",
      "study --> studi\n",
      "studying --> studi\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "  print(i,\"-->\",ps.stem(i))\n",
    "\n",
    "# it is not working with the word that ends with y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1FevaDIgGBE"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15ucwfOpgs46"
   },
   "outputs": [],
   "source": [
    "words.extend([\"playing\",\"helping\",\"happiness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOi0M2JzgObZ"
   },
   "outputs": [],
   "source": [
    "# dollar is used for removing from last.\n",
    "rs = RegexpStemmer('ing$|s$|ed$|es$|able$|ness$', min=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7bm4hzfgc6y",
    "outputId": "07ba95f0-e793-4ba4-fc83-fe292dfe5c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flyed --> fly\n",
      "history --> history\n",
      "killing --> kill\n",
      "killed --> kill\n",
      "jumping --> jump\n",
      "jumped --> jump\n",
      "study --> study\n",
      "studying --> study\n",
      "playing --> play\n",
      "helping --> help\n",
      "happiness --> happi\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "  print(i,\"-->\",rs.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6LDYnYmqgKi"
   },
   "source": [
    "###**Wordnet Lemmatizer :-**\n",
    "* It is a tool in NLP that reduces a word to its base or dictionary form know as lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j95LptxvrIxs"
   },
   "source": [
    "**Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFQAcl1brMRc",
    "outputId": "2163d1f7-cbda-4c8e-a9cb-7a3f61d0bd2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnbrsqMBrQmy"
   },
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trug5vYorT0w",
    "outputId": "2318676c-0a93-42a5-8f35-e438f9437d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flyed --> fly\n",
      "history --> history\n",
      "killing --> kill\n",
      "killed --> kill\n",
      "jumping --> jump\n",
      "jumped --> jump\n",
      "study --> study\n",
      "studying --> study\n",
      "playing --> play\n",
      "helping --> help\n",
      "happiness --> happiness\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "  print(i,\"-->\",wl.lemmatize(i, pos = \"v\"))    # v stands for verd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0ZQdyQrnAc_"
   },
   "outputs": [],
   "source": [
    "a = [\"playing\",\"was\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6FRm9dEmRZR",
    "outputId": "2bf383ac-a1b3-46e3-9139-a3ec1ec8f39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing --> play\n",
      "was --> be\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "  print(i,\"-->\",wl.lemmatize(i, pos = \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puHfpY8-nFqr",
    "outputId": "cc251daf-5d1c-414d-b4dd-b5ee4037d06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n",
      "good\n",
      "mouse\n",
      "mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"better\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "\n",
    "print(lemmatizer.lemmatize(\"mice\"))\n",
    "print(lemmatizer.lemmatize(\"mice\", pos=\"n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pmZNIdnivv-"
   },
   "source": [
    "##**One hot encoder:-**\n",
    "* To convert text data intoo no. format so that machine can understand the model.\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "###**Advantages**\n",
    "1. It is easy to apply and make it clear which word is which.\n",
    "2. words are treated equally like cat is not greater than dog both are same for the machine.\n",
    "3. good fit for the small data.\n",
    "\n",
    "###**Disadvantages**\n",
    "1. it doesn't understand that dog and cat are related to each other like which one is hot and cold for hotencoder.\n",
    "     * Hot\n",
    "     * Cold\n",
    "2. Does not work with the large data set.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97PTJVy-knga"
   },
   "source": [
    "##**BOW(Bag of Words)**\n",
    "1. The HOD is good.\n",
    "2. The Class is bad.\n",
    "3. the teacher is worst.\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "* It remove all stopwords.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awqz3eFWlgDG",
    "outputId": "def53ab8-3bc2-4cfe-a31c-8ad41201362e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6xxTMuzl1IW"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNlRgOQelXbL"
   },
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Data science is the interdisciplinary field that uses scientific methods, algorithms,\n",
    "and systems to extract knowledge and insights from data. It involves collecting,\n",
    "cleaning, analyzing, and interpreting large amounts of data to uncover hidden patterns,\n",
    "trends, and relationships, ultimately informing decision-making and problem-solving.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNxAsTzzl0Iq",
    "outputId": "28ceb112-af8e-428c-d6e4-a4a3b780fae2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjObmN7mnPQv",
    "outputId": "c59a282e-7fbd-4e1f-bdbe-0f10953650e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rrY_-yQn-Ix"
   },
   "outputs": [],
   "source": [
    "text = paragraph.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkauNeOEoDRe"
   },
   "outputs": [],
   "source": [
    "wt = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0oAiTg3oIDc",
    "outputId": "ded15622-92b0-4151-f20e-2a90b18ef247"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'the',\n",
       " 'interdisciplinary',\n",
       " 'field',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'and',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'insights',\n",
       " 'from',\n",
       " 'data',\n",
       " '.',\n",
       " 'it',\n",
       " 'involves',\n",
       " 'collecting',\n",
       " ',',\n",
       " 'cleaning',\n",
       " ',',\n",
       " 'analyzing',\n",
       " ',',\n",
       " 'and',\n",
       " 'interpreting',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'data',\n",
       " 'to',\n",
       " 'uncover',\n",
       " 'hidden',\n",
       " 'patterns',\n",
       " ',',\n",
       " 'trends',\n",
       " ',',\n",
       " 'and',\n",
       " 'relationships',\n",
       " ',',\n",
       " 'ultimately',\n",
       " 'informing',\n",
       " 'decision-making',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfVnW166oTXk"
   },
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for words in wt:\n",
    "    if words not in stopwords.words(\"english\"):\n",
    "      new_words.append(words)\n",
    "      \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLUKb0o8pmaf",
    "outputId": "4ed68f5b-88b4-4a07-deb1-2ab9ccb98a6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'science',\n",
       " 'interdisciplinary',\n",
       " 'field',\n",
       " 'uses',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'systems',\n",
       " 'extract',\n",
       " 'knowledge',\n",
       " 'insights',\n",
       " 'data',\n",
       " '.',\n",
       " 'involves',\n",
       " 'collecting',\n",
       " ',',\n",
       " 'cleaning',\n",
       " ',',\n",
       " 'analyzing',\n",
       " ',',\n",
       " 'interpreting',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'uncover',\n",
       " 'hidden',\n",
       " 'patterns',\n",
       " ',',\n",
       " 'trends',\n",
       " ',',\n",
       " 'relationships',\n",
       " ',',\n",
       " 'ultimately',\n",
       " 'informing',\n",
       " 'decision-making',\n",
       " 'problem-solving',\n",
       " '.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcuVza4js_z-",
    "outputId": "50658223-c0a5-4478-c43e-baa8882c15aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPNlQNvM3d-N"
   },
   "source": [
    "* CC --> Coordinating Conjunction\n",
    "* CD --> Cardinal Digit\n",
    "* DT --> Determiner\n",
    "* EX -->existential there (like \"there is\")\n",
    "* FW --> foreign word\n",
    "* IN --> preposition/subordinating conjunction\n",
    "* JJ --> adjective\n",
    "* JJR --> adjective comparative\n",
    "* JJS --> adjective superlative\n",
    "* LS --> list marker\n",
    "* MD --> modal-couls, will\n",
    "* NN --> noun, singular\n",
    "* NNP --> proper noun, singular\n",
    "* NNPS --> proper noun, plural\n",
    "* PDT --> predeterminer - \"all the kids\"\n",
    "* POS --> possessive ending parent's\n",
    "* PRP --> personal pronoun - I, He, She\n",
    "* PRP$ --> possesive pronoun - my, his, hers\n",
    "* RD --> adverb - very, silently\n",
    "* RBR --> adverb, comparative - better\n",
    "* RBS --> adverb, superlative - best\n",
    "* RP --> particule - give up\n",
    "* TO --> to go \"to\" the store\n",
    "* UH --> interjection - errrrrrrm\n",
    "* VB --> verb, base form - take\n",
    "* VBD --> verb, past tense - took\n",
    "* VBG --> verb, sing. present, non-3ed - take\n",
    "* VBZ --> verb, 3ed person sing. present - take\n",
    "* WDT --> wh-determiner - Which\n",
    "* WP --> wh- pronoun- who, what\n",
    "* WP$ --> possesive wh-pronoun, eg-whose\n",
    "* WRB --> wh-adverb,Â eg-where,Â when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGf2Am2Dtahf",
    "outputId": "ea72c66a-a30e-45b1-d84e-913c20c1ee34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpWKPkgp1r0d"
   },
   "outputs": [],
   "source": [
    "word ="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
